{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcceea53-dc3c-4980-a54d-7827a6032913",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(httr)\n",
    "library(stringr)\n",
    "\n",
    "\n",
    "tokenize <- function(text) {\n",
    "  # Convert to lowercase\n",
    "  text <- tolower(text)\n",
    "  \n",
    "  # Extract words (remove punctuation)\n",
    "  # Using regex pattern to match word boundaries\n",
    "  tokens <- str_extract_all(text, \"\\\\b\\\\w+\\\\b\")[[1]]\n",
    "  \n",
    "  return(tokens)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c04406-f11f-42a6-b87b-90b3ce47eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngrams <- function(tokens, n) {\n",
    "  ngrams <- list()\n",
    "  \n",
    "  # Create n-grams by sliding window\n",
    "  for (i in 1:(length(tokens) - n + 1)) {\n",
    "    ngram <- tokens[i:(i + n - 1)]\n",
    "    ngrams[[i]] <- ngram\n",
    "  }\n",
    "  \n",
    "  return(ngrams)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afad715-a569-4ec6-8411-65b4ab007e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(ngrams) {\n",
    "  # Use environment as dictionary/table\n",
    "  table <- new.env(hash = TRUE)\n",
    "  \n",
    "  for (gram in ngrams) {\n",
    "    # Prefix is all words except last\n",
    "    prefix <- paste(gram[1:(length(gram) - 1)], collapse = \" \")\n",
    "    \n",
    "    # Next word is the last word\n",
    "    next_word <- gram[length(gram)]\n",
    "    \n",
    "    # Add to table (append to list)\n",
    "    if (exists(prefix, envir = table)) {\n",
    "      table[[prefix]] <- c(table[[prefix]], next_word)\n",
    "    } else {\n",
    "      table[[prefix]] <- c(next_word)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(table)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fc021f-5902-4add-8102-e6c1bf91852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n = 2) {\n",
    "  tokens <- tokenize(text)\n",
    "  ngrams <- make_ngrams(tokens, n)\n",
    "  table <- build_ngram_table(ngrams)\n",
    "  \n",
    "  return(table)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c28c21c-f9c7-4562-ad60-7ecf5ef94688",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n = 2) {\n",
    "  # Fetch URL content\n",
    "  response <- GET(url)\n",
    "  text <- content(response, \"text\", encoding = \"UTF-8\")\n",
    "  \n",
    "  # Use digest_text\n",
    "  return(digest_text(text, n))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06497ec8-2082-46d2-a03d-43f4fcbf619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(table) {\n",
    "  # Get all keys (prefixes)\n",
    "  keys <- ls(table)\n",
    "  \n",
    "  # Return random choice\n",
    "  return(sample(keys, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2389e44-cae9-4913-a161-f5e459f9d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next <- function(prefix, table) {\n",
    "  # Check if prefix exists in table\n",
    "  if (!exists(prefix, envir = table)) {\n",
    "    return(NULL)\n",
    "  }\n",
    "  \n",
    "  # Get possible next words\n",
    "  options <- table[[prefix]]\n",
    "  \n",
    "  # Return random choice from options\n",
    "  return(sample(options, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97269aed-dbb7-4941-a978-de04e2378ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate <- function(text_or_url, n = 2, start = NULL, length = 50) {\n",
    "  # Decide if input is URL\n",
    "  if (grepl(\"^http\", text_or_url)) {\n",
    "    table <- digest_url(text_or_url, n)\n",
    "  } else {\n",
    "    table <- digest_text(text_or_url, n)\n",
    "  }\n",
    "  \n",
    "  # Prepare start prefix\n",
    "  if (is.null(start)) {\n",
    "    # Use random start\n",
    "    prefix <- random_start(table)\n",
    "  } else {\n",
    "    # Tokenize start words\n",
    "    t <- tokenize(start)\n",
    "    \n",
    "    # Check if enough start words\n",
    "    if (length(t) < (n - 1)) {\n",
    "      stop(\"Not enough start words\")\n",
    "    }\n",
    "    \n",
    "    # Take last (n-1) words and create prefix\n",
    "    prefix <- paste(tail(t, n - 1), collapse = \" \")\n",
    "  }\n",
    "  \n",
    "  # Generate words\n",
    "  result <- unlist(strsplit(prefix, \" \"))\n",
    "  \n",
    "  for (i in 1:length) {\n",
    "    # Get current prefix\n",
    "    current_prefix <- paste(tail(result, n - 1), collapse = \" \")\n",
    "    \n",
    "    # Predict next word\n",
    "    next_word <- predict_next(current_prefix, table)\n",
    "    \n",
    "    # Stop if no next word found\n",
    "    if (is.null(next_word)) {\n",
    "      break\n",
    "    }\n",
    "    \n",
    "    # Add to result\n",
    "    result <- c(result, next_word)\n",
    "  }\n",
    "  \n",
    "  # Return as single string\n",
    "  return(paste(result, collapse = \" \"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb126ca8-d9dd-4165-9f9e-f4288b18f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a(i) Grimm's Fairy Tales - Start: 'the king', n=3, length=15:\n",
      "[1] \"the king said to the king and told him the silken cord for then the peasant in\"\n",
      "\n",
      "2a(ii) Grimm's Fairy Tales - Random start, n=3, length=15:\n",
      "[1] \"sprinkled salt upon it i cannot and dare not take pity on her dress blackened her face\"\n"
     ]
    }
   ],
   "source": [
    "# Question 2a - Grimm's Fairy Tales\n",
    "# Set seed as required\n",
    "set.seed(2025)\n",
    "\n",
    "# URL for Grimm's Fairy Tales\n",
    "grimm_url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "# i) Using n=3, with start words \"the king\", length=15\n",
    "cat(\"2a(i) Grimm's Fairy Tales - Start: 'the king', n=3, length=15:\\n\")\n",
    "result_2a_i <- generate(grimm_url, n = 3, start = \"the king\", length = 15)\n",
    "print(result_2a_i)\n",
    "\n",
    "# Reset seed for reproducibility\n",
    "set.seed(2025)\n",
    "\n",
    "# ii) Using n=3, with no start word, length=15\n",
    "cat(\"\\n2a(ii) Grimm's Fairy Tales - Random start, n=3, length=15:\\n\")\n",
    "result_2a_ii <- generate(grimm_url, n = 3, start = NULL, length = 15)\n",
    "print(result_2a_ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b42ab60-a76b-47e9-8565-c8e598d7bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2b(i) Ancient Armour - Start: 'the king', n=3, length=15:\n",
      "[1] \"the king and many fell in death among their children 244 the last item we see from\"\n",
      "\n",
      "2b(ii) Ancient Armour - Random start, n=3, length=15:\n",
      "[1] \"l estoc stabbing sword is named in the form of this century it is vain to inquire\"\n"
     ]
    }
   ],
   "source": [
    "# Question 2b - Ancient Armour and Weapons in Europe\n",
    "# Reset seed\n",
    "set.seed(2025)\n",
    "\n",
    "# URL for Ancient Armour\n",
    "armour_url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "\n",
    "# i) Using n=3, with start words \"the king\", length=15\n",
    "cat(\"\\n2b(i) Ancient Armour - Start: 'the king', n=3, length=15:\\n\")\n",
    "result_2b_i <- generate(armour_url, n = 3, start = \"the king\", length = 15)\n",
    "print(result_2b_i)\n",
    "\n",
    "# Reset seed for reproducibility\n",
    "set.seed(2025)\n",
    "\n",
    "# ii) Using n=3, with no start word, length=15\n",
    "cat(\"\\n2b(ii) Ancient Armour - Random start, n=3, length=15:\\n\")\n",
    "result_2b_ii <- generate(armour_url, n = 3, start = NULL, length = 15)\n",
    "print(result_2b_ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0268043-a6e9-4d3b-9d66-d696bf3e8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grimms Fairy Tales generates narrative text with story elements like characters and \n",
    "emotions, while Ancient Armour produces technical, historical language focused on weapons and medieval warfare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "\n",
    "A language model (often called a Language Learning Model or LLM - Large Language Model) is a type of machine learning model that predicts the probability of a sequence of words to understand and generate human language. At its core, a language model is a probability distribution over words. It takes input text as context and predicts the most likely next word (or token) based on patterns learned from training data. Modern language models like ChatGPT, Claude, and Gemini use this principle: they analyze previous words in a sequence and generate the next most appropriate word, continuing this process to produce coherent text.\n",
    "\n",
    "Language models range from simple statistical models (like the n-gram models I built in Questions 1 and 2) to complex neural network-based transformers that use attention mechanisms to understand context across long sequences of text. The key difference is that advanced models can \"pay attention\" to relevant parts of the input text contextually, rather than just looking at a fixed window of previous words.\n",
    "\n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?\n",
    "\n",
    "To run a language model locally (offline, on your own computer), you need to use local-first LLM tools that download and execute models without requiring an internet connection. Popular tools include:\n",
    "\n",
    "1. **Ollama** - Simple command-line tool where you download models with `ollama pull <model_name>` and run them locally\n",
    "2. **LM Studio** - User-friendly desktop application with a graphical interface for downloading and chatting with models offline\n",
    "3. **GPT4All** - Downloadable application that runs over 1,000 open-source models locally without internet\n",
    "4. **Llamafile** - Converts language models into executable files that run on any platform with no installation\n",
    "\n",
    "The process involves downloading a model file (usually in GGUF format) to your computer, then using one of these tools to load and run it. All processing happens on your machine, so no data leaves your computer and it works completely offline once the model is downloaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | The shell is the program that interprets and executes the commands we type. When I type `mkdir project`, the shell reads that command, figures out what program needs to run (the mkdir program), and tells the operating system to execute it. Basically it's the intermediary between me typing commands and the computer actually doing something. |\n",
    "| **Terminal emulator** | A terminal emulator is the application window where I'm actually typing the command. It's called an emulator because back in the day people used physical terminals (like hardware devices), but now we just have software that emulates those old terminals. When I open Terminal on my computer and type `mkdir project`, I'm using a terminal emulator. |\n",
    "| **Process** | A process is a running program. When I type `mkdir project` and hit enter, the shell creates a new process to run the mkdir program. That process does its job (creating the directory) and then terminates. Every time a command runs, it becomes a process. |\n",
    "| **Signal** | A signal is a way to send messages to processes, usually to interrupt or stop them. This doesn't really apply to `mkdir project` since that command runs so quickly, but an example would be if I was running a long command and pressed Ctrl+C to stop it - that sends a signal to kill the process. |\n",
    "| **Standard input** | Standard input (stdin) is where a program reads input from, usually the keyboard. For `mkdir project`, this doesn't really apply because mkdir doesn't read any input - it just takes the directory name as a command line argument and creates it. An example where stdin matters would be something like `cat`, which reads from stdin if you don't give it a file. |\n",
    "| **Standard output** | Standard output (stdout) is where a program sends its normal output, usually to the screen. For `mkdir project`, there's actually no output to stdout if it succeeds - it just silently creates the directory. But if I ran `ls`, the list of files would be sent to stdout and displayed on my screen. |\n",
    "| **Command line argument** | Command line arguments are the extra information we give to a command. In `mkdir project`, \"project\" is the command line argument - it's telling mkdir what directory name to create. The shell passes this argument to the mkdir program when it runs. |\n",
    "| **The environment** | The environment is a set of variables that programs can access to get information about the system and user settings. For `mkdir project`, the environment might include things like the PATH variable (which tells the shell where to find the mkdir program) or the current working directory. These environment variables affect how commands run. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "\n",
    "The programs are:\n",
    "- **find** - searches for files and directories\n",
    "- **xargs** - takes input from one command and converts it into arguments for another command\n",
    "- **grep** - searches for text patterns within files\n",
    "\n",
    "#### b) Explain what this command is doing, part by part.\n",
    "\n",
    "`find .` - This searches for files starting in the current directory (the dot means current directory). It will look through all subdirectories too.\n",
    "\n",
    "`-iname \"*.R\"` - This tells find to look for files with names that match the pattern `*.R`. The `-iname` flag means it's case-insensitive, so it will find files ending in `.R`, `.r`, or any combination of uppercase and lowercase letters.\n",
    "\n",
    "`|` - This is a pipe. It takes the output from the find command (the list of R files that were found) and sends it to the next command.\n",
    "\n",
    "`xargs grep read_csv` - This takes the list of R files from find and passes them as arguments to the grep command. grep then searches through each of those R files looking for lines that contain the text \"read_csv\". So basically, it's searching all R files in the current directory and its subdirectories for any occurrences of the function \"read_csv\".\n",
    "\n",
    "In plain English, this command finds all R files and then searches through them to see which ones contain the text \"read_csv\". This is useful if you want to know which R scripts in a project are reading in data using the `read_csv` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "\n",
    "Unable to find image 'hello-world:latest' locally\n",
    "latest: Pulling from library/hello-world\n",
    "17eec7bbc9d7: Pull complete\n",
    "Digest: sha256:f7931603f70e13dbd844253370742c4fc4202d290c80442b2e68706d8f33ce26\n",
    "Status: Downloaded newer image for hello-world:latest\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (amd64)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/\n",
    "\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "\n",
    "C:\\Users\\mckap>docker run --rm -p 8787:8787 -e PASSWORD=bios512 -v C:\\dockerwork:/home/rstudio rocker/rstudio\n",
    "Unable to find image 'rocker/rstudio:latest' locally\n",
    "latest: Pulling from rocker/rstudio\n",
    "2c9ba66d5dbe: Pull complete\n",
    "e4b9e87bb831: Pull complete\n",
    "3c7cdccc4be7: Pull complete\n",
    "39038e16d1ba: Pull complete\n",
    "3665120d345d: Pull complete\n",
    "971ba7cf0d8a: Pull complete\n",
    "5d246ec925db: Pull complete\n",
    "664fb1818bbb: Pull complete\n",
    "b71e78fefbbb: Pull complete\n",
    "890065c4c99d: Pull complete\n",
    "d923cf803a12: Pull complete\n",
    "2a63ed8b2250: Pull complete\n",
    "4b3ffd8ccb52: Pull complete\n",
    "999e4b8f7ed8: Pull complete\n",
    "9c1a4a0706b7: Pull complete\n",
    "191985778909: Pull complete\n",
    "08e74fd5985d: Pull complete\n",
    "62f215ca34c6: Pull complete\n",
    "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
    "Status: Downloaded newer image for rocker/rstudio:latest\n",
    "[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n",
    "[s6-init] ensuring user provided files have correct perms...exited 0.\n",
    "[fix-attrs.d] applying ownership & permissions fixes...\n",
    "[fix-attrs.d] done.\n",
    "[cont-init.d] executing container initialization scripts...\n",
    "[cont-init.d] 01_set_env: executing...\n",
    "skipping /var/run/s6/container_environment/HOME\n",
    "skipping /var/run/s6/container_environment/PASSWORD\n",
    "skipping /var/run/s6/container_environment/RSTUDIO_VERSION\n",
    "[cont-init.d] 01_set_env: exited 0.\n",
    "[cont-init.d] 02_userconf: executing...\n",
    "[cont-init.d] 02_userconf: exited 0.\n",
    "[cont-init.d] done.\n",
    "[services.d] starting services\n",
    "[services.d] done.\n",
    "\n",
    "#### c) How do you log in to the RStudio server?\n",
    "\n",
    "To log in to the RStudio server, I opened my web browser and navigated to `http://localhost:8787`. This displayed the RStudio Server login page. I entered \"rstudio\" as the username (the default username for the rocker/rstudio container) and \"bios512\" as the password (which I set using the `-e PASSWORD=bios512` flag in the docker run command). After clicking the Sign In button, RStudio Server loaded in my browser and I could access my mounted files in the Files pane.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
